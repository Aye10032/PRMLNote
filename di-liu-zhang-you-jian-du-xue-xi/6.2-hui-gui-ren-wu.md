# 6.2 回归任务

## 6.2.1 线性回归

{% hint style="success" %}

线性回归在分类上属于判别函数

{% endhint %}



- **输入**：N个<mark style="color:orange;">**独立同分布（i.i.d）**</mark>的训练样本$$(\mathbf{x}^i,y^i)\in X\times R$$，$$i=1,2,\dots,N$$
- **目标函数**：$$f\in \mathcal{F}$$
- **损失函数**：$$L(f;x,y) = (f(x)-y)^2$$
- **期望风险**：$$\int (f(x)-y)^2dP(x,y)$$
- 当$$f$$是线性函数，则最优化问题为：

$$
\min_\limits{\mathbf{w}} J(\mathbf{w}) = \sum_{i=1}^N(\mathbf{w}^T\mathbf{x}^i - y^i)^2
$$

最小化<mark style="color:purple;">**经验风险**</mark>，在这里即为<mark style="color:orange;">**最小二乘/均方误差**</mark>



### 梯度下降

对于上述最优化问题，采用梯度下降法进行更新，梯度为
$$
\frac{\partial J(\mathbf{w})}{\partial w_j} = 2\sum_{i=1}^Nx_j^i(\mathbf{w}^T\mathbf{x}^i - y^i)
$$
对于梯度下降法，更新规则为：
$$
w_j = w_j - 2\alpha\sum_{i=1}^Nx_j^i(\mathbf{w}^T\mathbf{x}^i - y^i),\ \alpha>0
$$
这里$$\alpha$$为<mark style="color:orange;">**学习率**</mark>

