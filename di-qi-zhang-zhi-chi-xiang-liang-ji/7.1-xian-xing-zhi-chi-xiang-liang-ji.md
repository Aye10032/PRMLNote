# 7.1 线性支持向量机

## 7.1.1 间隔

### 一、函数间隔

对于一个训练样本$$(\mathbf x^i,y^i)$$，它到$$(\mathbf w,b)$$确定的超平面的<mark style="color:purple;">**函数间隔**</mark>为：
$$
\hat{\gamma}^i = y^i(\mathbf w^T\mathbf x^i+b)
$$
<mark style="color:orange;">**函数间隔与距离是正相关的**</mark>



- $$y^i=1$$，$$(\mathbf w^T\mathbf x^i + b)$$是一个大的正数
- $$y^i=-1$$，$$(\mathbf w^T\mathbf x^i + b)$$是一个比较小的负数
- $$y^i(\mathbf w^T\mathbf x^i+b)>0$$，说明模型对样本的预测是正确的
- <mark style="color:red;">**大的函数间隔→高的预测置信度**</mark>



对于训练数据集$$S = \{(\mathbf x^i,y^i),\ i=1,\dots,N\}$$，它的函数间隔定义为所有样本中<mark style="color:orange;">**最小的**</mark>那个：
$$
\hat{\gamma} = \min_i \hat{\gamma}^i,\ i=1,\dots,N
$$


### 二、几何间隔

![](../.gitbook/assets/7.1.1.png)

对于样本$$(\mathbf x^i,y^i)$$，$$y^i=1$$，它到决策面的距离$$\gamma^i$$是线段AB的长度

其中，点B可以表示为：
$$
\mathbf x^i - \frac{\gamma^i\mathbf w}{\Vert \mathbf w\Vert_2}
$$
由于点B在<mark style="color:purple;">**决策边界**</mark>上，即：
$$
\mathbf w^T\left(\mathbf x^i - \frac{\gamma^i\mathbf w}{\Vert \mathbf w\Vert_2}\right) + b = 0
$$
求解此方程可以得到样本$$(\mathbf x^i,y^i)$$的<mark style="color:purple;">**几何间隔**</mark>为：
$$
\gamma^i = y^i\left(\left(\frac{\mathbf w}{\Vert\mathbf w\Vert_2}\right)^T\mathbf x^i + \frac{b}{\Vert\mathbf w\Vert_2}\right)
$$
同样的，对于训练数据集$$S = \{(\mathbf x^i,y^i),\ i=1,\dots,N\}$$，关于判别界面的几何间隔为：
$$
\gamma = \min_i \gamma^i,\ i=1,\dots,N
$$


**函数间隔与几何间隔的关系**：
$$
\gamma^i = \frac{\hat{\gamma}^i}{\Vert \mathbf w\Vert_2}
\\
\gamma = \frac{\hat{\gamma}}{\Vert \mathbf w\Vert_2}
$$
显然，若$$\Vert \mathbf w\Vert_2=1$$，则二者相等



<mark style="color:red;">**几何间隔具有不变性**</mark>



### 三、最优间隔分类器

