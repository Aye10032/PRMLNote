# 4.1 模式类别可分性的测度

## 4.1.1 概述

{% hint style="warning" %}

特征选择和提取是模式识别中的一个关键问题

{% endhint %}



- 如果将数目很多的测量值不做分析，全部直接用作分类特征，不但耗时，而且会影响到分类的效果，产生<mark style="color:purple;">**特征维数灾难**</mark>问题
- 为了设计出效果好的分类器，通常需要对原始的测量值集合进行分析，经过选择或变换处理，组成有效的识别特征
- 在保证一定分类精度的前提下，减少特征维数，即进行<mark style="color:orange;">**降维**</mark>处理，使分类器实现快速、准确和高效的分类
- 为达到上述目的，关键是所提供的识别特征应具有很好的可分性，使分类器容易判别。为此，需对特征进行选择
  - 去掉模棱两可、不易判别的特征
  - 所提供的特征不要重复，即去掉那些相关性强且没有增加更多分类信息的特征





## 4.1.2 特征选择和提取

**特征选择**：从$$n$$个度量值集合$$\left\{x_1,x_2,\dots,x_n\right\}$$中，按照某一准则<mark style="color:orange;">**选取**</mark>出供分类的<mark style="color:purple;">**子集**</mark>，作为降维的分类特征



**特征提取**：使$$\{x_1,x_2,\dots,x_n\}$$通过某种<mark style="color:orange;">**变换**</mark>，产生$$m$$个特征作为新的分类特征（也称为<mark style="color:purple;">**二次特征**</mark>）



上述两种方法的目的都是为了在尽可能保留识别信息的前提下，降低特征空间的维数，已达到有效的分类。



## 4.1.3 模式类别可分性的测度

### 一、点到点之间的距离

在n维空间中，两点a、b之间的欧式距离为：
$$
D(a,b)= \Vert a-b\Vert
$$
写成距离平方的形式：
$$
\begin{align}
D^2(a,b)&=(a-b)^T(a-b) \nonumber
\\
&=\sum_{k=1}^n(a_k-b_k)^2 \nonumber
\end{align}
$$
其中，$$a_k$$、$$b_k$$为向量$$\boldsymbol{a},\boldsymbol{b}$$的第k个分量



### 二、点到点集之间的距离

在n维空间中，点$$x$$到点$$a^{(i)}$$之间的距离平方为：
$$
D^2(x,a^{(i)})=\sum_{k-=1}^n(x_k-a_k^{(i)})^2
$$
带入得点$$x$$到点集$$\{a^{(i)}\}_{i=1,2,\dots,k}$$之间的<mark style="color:orange;">**均方距离**</mark>为：
$$
\begin{align}
\overline{D^2(x,a^{(i)})} &= \frac{1}{K}\sum_{i=1}^KD^2(x,a^{(i)}) \nonumber
\\
&= \frac{1}{K}\sum_{i=1}^K\left\{\sum_{k-=1}^n(x_k-a_k^{(i)})^2\right\}
\end{align}
$$


### 三、类内距离

n维空间中同一类内各模式样本点集$$\{a^{(i)}\}_{i=1,2,\dots,K}$$，其内部各点的<mark style="color:purple;">**均方距离**</mark>为：
$$
\overline{D^2(\{a^{(j)}\}, \{a^{(i)}\})} = \frac{1}{K}\sum_{j=1}^K\left[\frac{1}{K-1}\sum_{\substack{i=1\\i\neq j}}^K\sum_{k=1}^n(a_k^{(j)}-a_k^{(i)})^2\right]
$$
此外，可证明：
$$
\overline{D^2}=2\sum_{k=1}^n\sigma_k^2
$$
其中，$$\sigma_k^2$$为$$\{a^{(i)}\}$$在第k个份量上的<mark style="color:purple;">**无偏方差**</mark>：
$$
\sigma_k^2=\frac{1}{K-1}\sum_{i=1}^K(a_k^{(i)}-\overline{a_k})^2
$$
其中，$$\overline{a_k}$$为$$a^{(i)}$$在第k个分量上的<mark style="color:purple;">**均值**</mark>：
$$
\overline{a_k} = \frac{1}{K}\sum_{i=1}^Ka_k^{(i)}
$$
证明略



### 四、类内散布矩阵

一类内各模式样本点集$$\{a^{(i)}\}_{i=1,2,\dots,K}$$，其<mark style="color:orange;">**类内散布矩阵**</mark>为：
$$
S=\sum_{i=1}^K\{(a^{(i)}-m)(a^{(i)}-m)^T\}
$$
其中
$$
m=\frac{1}{K}\sum_{i=1}^Ka^{(i)}
$$
{% hint style="success" %}

类内散布矩阵表示各样本点围绕其均值周围的散布情况

{% endhint %}



### 五、类间距离和类间散布矩阵

两个点集的距离$$\overline{D^2(\{a^{(i)}\}, \{b^{(j)}\})}_{i=1,2,\dots,K_a;j=1,2,\dots,K_b}$$对类别的可分性起着重要的作用，为简化起见，常用两类样本各自质心间的距离作为<mark style="color:orange;">**类间距离**</mark>，并假设两类样本出现的概率相等，则：
$$
D^2=\sum_{k=1}^n(\boldsymbol{m}_{1_k}-\boldsymbol{m}_{2_k})^2
$$
其中，$$\boldsymbol{m}_1$$和$$\boldsymbol{m}_2$$为两类模式样本集各自的<mark style="color:purple;">**均值向量**</mark>，$$\boldsymbol{m}_{1_k}$$和$$\boldsymbol{m}_{2_k}$$为各自的第k个<mark style="color:purple;">**分量**</mark>，n为<mark style="color:purple;">**维数**</mark>



这两个模式的<mark style="color:purple;">**类间散布矩阵**</mark>为：
$$
S_{b2}=(m_1-m_2)(m_1-m_2)^T
$$


扩展到三个以上的类别，<mark style="color:orange;">**类间散布矩阵**</mark>可以写作：
$$
S_b = \sum_{i=1}^cP(\omega_i)(m_i-m_0)(m_i-m_0)^T
$$
其中，$$m_0$$为多类模式分布的<mark style="color:purple;">**总体均值向量**</mark>，c为类别数量：
$$
m_0=E\{x\}=\sum_{i=1}^cp(\omega_i)m_i,\ \forall\omega_i,i=1,2,\dots,c
$$


### 六、多类模式集散布矩阵

<mark style="color:red;">**多类情况**</mark>的<mark style="color:orange;">**类内散布矩阵**</mark>，可以写成各类的类内散布矩阵的<mark style="color:purple;">**先验概率的加权和**</mark>：
$$
\begin{align}
S_w &=\sum_{i=1}^cP(\omega_1)E\{(x-m_i)(x-m_i)^T\vert\omega_i\} \nonumber
\\
&=\sum_{i=1}^cP(\omega_i)C_i \nonumber
\end{align}
$$
其中，$$C_i$$是第i类的<mark style="color:purple;">**协方差矩阵**</mark>



有时，使用多类模式<mark style="color:purple;">**总体分布的散布矩阵**</mark>来反映其可分性，即：
$$
S_t = E\{(x-m_0)(x-m_0)^T\},\ \ x\in\forall,i=1,2,\dots,c
$$
其中$$\boldsymbol{m}_0$$为多类模式分布的<mark style="color:purple;">**总体均值向量**</mark>



### 七、关系

{% hint style="success" %}

总体散布矩阵是各类类内散布矩阵与类间散布矩阵之和

{% endhint %}

$$
S_t = S_w+S_b
$$
