# 5.2 统计机器学习

## 5.2.1 统计机器学习的框架

- **输入**：<mark style="color:orange;">**独立同分布**</mark>的训练样本$$(x_i,y_i)\in X\times Y,i=1,2,\dots,N$$
  - 回归问题：Y是连续的
  - 分类问题：Y是类别
  - 排序问题：Y是序数
- **目标函数**：$$f\in \mathcal{F}$$
- **损失函数**：$$L(f;x,y)$$
- **期望风险**：$$\int L(f;x,y)dP(x,y)$$



## 5.2.2 回归及分类问题的最优函数

### 一、回归问题

- **输入**：<mark style="color:orange;">**独立同分布**</mark>的训练样本$$(x_i,y_i)\in X\times Y,i=1,2,\dots,N$$
- **目标函数**：$$f\in \mathcal{F}$$
  - 线性回归：f是线性的
  - 广义线性：f是非线性的
- **损失函数**：$$L(f;x,y)=(f(x)-y)^2$$
- **期望风险**：$$\int (f(x)-y)^2dP(x,y)$$



### 二、回归问题的最优函数

$$
\begin{align}
&\int (f(x)-y)^2dP(x,y) \nonumber
\\
=&\iint(f(x) - y)^2p(x,y)dxdy \nonumber
\\
=&\iint(f^2(x) - 2yf(x) + y^2)p(y\vert x)p(x)dxdy \nonumber
\\
=&\int\left[\int (f^2(x) - 2yf(x) + y^2)p(y\vert x)p(x)dy\right]dx \nonumber
\\
=&\int Q(f(x),y)p(x)dx \nonumber
\end{align}
$$

其中，$$Q(f(x),y)=f^2(x)-2E(y\vert x)f(x) + E(y^2\vert x)$$

关于$$f(x)$$求导并令其等于0，即可得到上述问题的解：
$$
f(x) = E(y\vert x)=\int yp(y\vert x)dy
$$


{% hint style="success" %}

<mark style="color:orange;">**最小化均方误差**</mark>（MSE）的回归函数是由有条件分布$$p(y\vert x)$$的y的均值给出

{% endhint %}



### 三、分类问题

- **输入**：<mark style="color:orange;">**独立同分布**</mark>的训练样本$$(x_i,y_i)\in X\times Y,i=1,2,\dots,N$$
- **目标函数**：$$f\in \mathcal{F}$$
- **损失函数**：$$L(f;x,y)=I_{\{f(x)\neq y\}}$$
- **期望风险**：$$\int I_{\{f(x)\neq y\}}dP(x,y)=P(f(x)\neq y)$$



### 四、分类问题的最优函数

要求的是<mark style="color:purple;">**最小期望风险**</mark>：
$$
\begin{align}
& \int I_{\{f(x)\neq y\}}dP(x,y) \nonumber
\\
=& P(f(x)\neq y) \nonumber
\\
=&\sum_{f(x)\neq C_i}P(C_i \vert x)p(x) \nonumber
\end{align}
$$
{% hint style="warning" %}

这里其实是求的<mark style="color:red;">**分类错误的概率**</mark>，因此需要将其最小化

{% endhint %}

因此，目标函数就是$$f(x)=\max\limits_{C_i}P(C_i\vert x)$$

{% hint style="success" %}

最小化0-损失的贝叶斯分类器选择具有最大条件分布$$p(y\vert x)$$的类标签

{% endhint %}


$$
\text{choose}\ C_i\ if P(C_i\vert x) = \max\limits_{k}P(C_k\vert x)
$$




## 5.2.3 过拟合和正则化



## 5.2.4 泛化能力分析
